{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer Encoder with Selective Learning",
      "provenance": [],
      "collapsed_sections": [
        "Z-SVfu0kalTi",
        "9gXV-3AMS3KJ",
        "JtzNGGNQ25oA",
        "L9A-PsxQ7HPs",
        "PEzxlUmi9FqD",
        "zoEPMLyv_MKD",
        "FNi-YzS3S3KO",
        "LjggRfX3S3KR"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wazib/CNN_FakeNews/blob/main/Transformer_Encoder_with_Selective_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnMEFP2yS3KI"
      },
      "source": [
        "# Text Classification using Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-SVfu0kalTi"
      },
      "source": [
        "#Downloading spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wioX-kCL83kl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99a6187-f3e1-487d-a32d-f2494901669c"
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_lg==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2022.5.18.1)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-py3-none-any.whl size=829180942 sha256=807f62bcf529847ae48ae38803dc97534c941336e8d0290a5db198e3223c519b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0tu6ajyd/wheels/11/95/ba/2c36cc368c0bd339b44a791c2c1881a1fb714b78c29a4cb8f5\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gXV-3AMS3KJ"
      },
      "source": [
        "# Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk_zJvhrS3KL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import backend as K \n",
        "import string\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AKgL-4BBWMe",
        "outputId": "595551ce-a1f9-4eaa-a244-eb76cfd376b8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixgszfcp_Xiz"
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk import word_tokenize, WordNetLemmatizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2ko-C0e8eN0"
      },
      "source": [
        "import spacy\n",
        "from tqdm import tqdm\n",
        "nlp = spacy.load('en_core_web_lg', parse=True, tag=True, entity=True)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rus_qsnLX94t"
      },
      "source": [
        "#Loading Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWU1uoRDFzbp",
        "outputId": "f52811f6-3584-4756-8f5c-dc29212f470d"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkHLOLsLxzr9"
      },
      "source": [
        "# IMDB Movie Reviews\n",
        "#Using only 10000 rows\n",
        "df = pd.read_csv('gdrive/My Drive/Data Sets/imdb-dataset/IMDB Dataset.csv', nrows=10000, engine='python',index_col=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2Kq0tdnSvl2"
      },
      "source": [
        "# IMDB Movie Reviews\n",
        "df = pd.read_csv('gdrive/My Drive/Data Sets/imdb-dataset/IMDB Dataset.csv', engine='python',index_col=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmKpoCJbwYVr",
        "outputId": "f128ad25-4b61-47f2-f61b-f8ed1add4fdd"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "w4zqC6j_dVQw",
        "outputId": "f9d513b0-e463-4a7a-e124-cdd7f3fe60f8"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               review sentiment\n",
              "0   One of the other reviewers has mentioned that ...  positive\n",
              "1   A wonderful little production. <br /><br />The...  positive\n",
              "2   I thought this was a wonderful way to spend ti...  positive\n",
              "3   Basically there's a family where a little boy ...  negative\n",
              "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "5   Probably my all-time favorite movie, a story o...  positive\n",
              "6   I sure would like to see a resurrection of a u...  positive\n",
              "7   This show was an amazing, fresh & innovative i...  negative\n",
              "8   Encouraged by the positive comments about this...  negative\n",
              "9   If you like original gut wrenching laughter yo...  positive\n",
              "10  Phil the Alien is one of those quirky films wh...  negative\n",
              "11  I saw this movie when I was about 12 when it c...  negative\n",
              "12  So im not a big fan of Boll's work but then ag...  negative\n",
              "13  The cast played Shakespeare.<br /><br />Shakes...  negative\n",
              "14  This a fantastic movie of three prisoners who ...  positive\n",
              "15  Kind of drawn in by the erotic scenes, only to...  negative\n",
              "16  Some films just simply should not be remade. T...  positive\n",
              "17  This movie made it into one of my top 10 most ...  negative\n",
              "18  I remember this film,it was the first film i h...  positive\n",
              "19  An awful film! It must have been up against so...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f379b1c1-6350-442c-8bcf-895ddb49cdb2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I saw this movie when I was about 12 when it c...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>This a fantastic movie of three prisoners who ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Kind of drawn in by the erotic scenes, only to...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Some films just simply should not be remade. T...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>This movie made it into one of my top 10 most ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I remember this film,it was the first film i h...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>An awful film! It must have been up against so...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f379b1c1-6350-442c-8bcf-895ddb49cdb2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f379b1c1-6350-442c-8bcf-895ddb49cdb2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f379b1c1-6350-442c-8bcf-895ddb49cdb2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtzNGGNQ25oA"
      },
      "source": [
        "#Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waWsZuX2MYGR"
      },
      "source": [
        "Adding start, end and sep token as sostoken, eostoken, septoken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6xYCAJ9M8ED"
      },
      "source": [
        "def special_token(ipstr):\n",
        "    #Adding the start token and end token\n",
        "    ipstr='sostoken '+ipstr+' eostoken'\n",
        "    #Adding septoken for new sentences\n",
        "    ipstr=re.sub('[.]+', ' septoken ', ipstr)\n",
        "    #Checking for the case where septoken is also the eostoken\n",
        "    ipstr=re.sub('septoken  eostoken', 'eostoken', ipstr)\n",
        "    return ipstr"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evtzP5hQSI7A"
      },
      "source": [
        "#Adding the special tokens\n",
        "text_special=[special_token(rev) for rev in df.review]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4MbU296jhjt"
      },
      "source": [
        "> Cleaning, lemmatizing and filtering length\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzrvLEnpjNoc"
      },
      "source": [
        "#Function for text cleaning, removing URL and \n",
        "#producing lowercase words with minimal punctuation\n",
        "def cleaning(ipstr):      \n",
        "    exclude = set(string.punctuation)\n",
        "\n",
        "    # remove new line and digits with regular expression\n",
        "    ipstr = re.sub(r'\\n', '', ipstr)\n",
        "    #ipstr = re.sub(r'\\d', '', ipstr)\n",
        "    # remove patterns matching url format\n",
        "    url_pattern = r'((http|ftp|https):\\/\\/)?[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;/~\\+#])?'\n",
        "    ipstr = re.sub(url_pattern, ' ', ipstr)\n",
        "    # remove non-ascii characters\n",
        "    ipstr = ''.join(character for character in ipstr if ord(character) < 128)\n",
        "    # remove punctuations\n",
        "    ipstr = ''.join(character for character in ipstr if character not in exclude)\n",
        "    # standardize white space\n",
        "    ipstr = re.sub(r'\\s+', ' ', ipstr)\n",
        "\n",
        "    # drop capitalization\n",
        "    ipstr = ipstr.lower()\n",
        "    #remove white space\n",
        "    ipstr = ipstr.strip()\n",
        "    \n",
        "    return ipstr\n",
        "\n",
        "def lenfilter(token_list):\n",
        "#    Remove single and double characters\n",
        "    return [word for word in token_list if len(word)>0]\n",
        "\n",
        "#Lemmatizing words\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "def token_lemmatize(token_list):\n",
        "    return [lemmatizer.lemmatize(t) for t in token_list]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKcV8sD7FXhD"
      },
      "source": [
        "#Cleaning Text\n",
        "text_clean=[cleaning(sen) for sen in text_special]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4lRitNI5emT"
      },
      "source": [
        "#Tokenizing\n",
        "tokens = [word_tokenize(sen) for sen in text_clean]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GFoCgwz_LDF"
      },
      "source": [
        "#Filtering single and double characters\n",
        "len_filtered_words = [lenfilter(sen) for sen in tokens]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLIGpgiR9dlg"
      },
      "source": [
        "result = [' '.join(sen) for sen in len_filtered_words]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788SrrxJ9dlg"
      },
      "source": [
        "df['Text_Final'] = result"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fBil8lX9dlh"
      },
      "source": [
        "df['Tokens'] = len_filtered_words"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMLF-avV6KS8"
      },
      "source": [
        "Converting output to categorical format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKzgjg96ZN1"
      },
      "source": [
        "pos_list=[]\n",
        "neg_list=[]\n",
        "for i in df['sentiment']:\n",
        "    if i=='positive':\n",
        "        pos_list.append(1)\n",
        "        neg_list.append(0)\n",
        "    elif i=='negative':\n",
        "        pos_list.append(0)\n",
        "        neg_list.append(1)\n",
        "df['pos']=pos_list\n",
        "df['neg']=neg_list\n",
        "label_names=['pos','neg']\n",
        "y_cat=df[label_names].values"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "7y5wKPMvSnww",
        "outputId": "02e66ed8-bc87-438e-b055-6bba6c135e41"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive   \n",
              "1  A wonderful little production. <br /><br />The...  positive   \n",
              "2  I thought this was a wonderful way to spend ti...  positive   \n",
              "3  Basically there's a family where a little boy ...  negative   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
              "\n",
              "                                          Text_Final  \\\n",
              "0  sostoken one of the other reviewers has mentio...   \n",
              "1  sostoken a wonderful little production septoke...   \n",
              "2  sostoken i thought this was a wonderful way to...   \n",
              "3  sostoken basically theres a family where a lit...   \n",
              "4  sostoken petter matteis love in the time of mo...   \n",
              "\n",
              "                                              Tokens  pos  neg  \n",
              "0  [sostoken, one, of, the, other, reviewers, has...    1    0  \n",
              "1  [sostoken, a, wonderful, little, production, s...    1    0  \n",
              "2  [sostoken, i, thought, this, was, a, wonderful...    1    0  \n",
              "3  [sostoken, basically, theres, a, family, where...    0    1  \n",
              "4  [sostoken, petter, matteis, love, in, the, tim...    1    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-798b0be8-6232-48a1-98b4-41f8e8ccd314\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Text_Final</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>pos</th>\n",
              "      <th>neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sostoken one of the other reviewers has mentio...</td>\n",
              "      <td>[sostoken, one, of, the, other, reviewers, has...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sostoken a wonderful little production septoke...</td>\n",
              "      <td>[sostoken, a, wonderful, little, production, s...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sostoken i thought this was a wonderful way to...</td>\n",
              "      <td>[sostoken, i, thought, this, was, a, wonderful...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>sostoken basically theres a family where a lit...</td>\n",
              "      <td>[sostoken, basically, theres, a, family, where...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sostoken petter matteis love in the time of mo...</td>\n",
              "      <td>[sostoken, petter, matteis, love, in, the, tim...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-798b0be8-6232-48a1-98b4-41f8e8ccd314')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-798b0be8-6232-48a1-98b4-41f8e8ccd314 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-798b0be8-6232-48a1-98b4-41f8e8ccd314');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9A-PsxQ7HPs"
      },
      "source": [
        "#Statistically Analyzing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8j-z7BxlxjN"
      },
      "source": [
        "Finding the distribution of length of text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Dsd6TnTO7LpJ",
        "outputId": "c5d3237d-7e85-4954-c6e3-607d265779a5"
      },
      "source": [
        "text_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['Text_Final']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.xlabel('Sequence Length')  \n",
        "plt.ylabel('Occurrences')  \n",
        "plt.title('Distribution of Sequence Length')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6tybSN07o9l"
      },
      "source": [
        "Percentage of text having length below a specified value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fXIsbAv7aEY",
        "outputId": "b7d54884-a4d4-4ff8-e64d-69b7793cd27d"
      },
      "source": [
        "cnt=0\n",
        "for i in df['Text_Final']:\n",
        "    if(len(i.split())<=512):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(df['Text_Final']))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.91592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrT6K97lfCsq"
      },
      "source": [
        "Finding the total number of words in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Nlde5wLfCEo",
        "outputId": "857a654b-d213-407d-a8fc-5e885cf5f8df"
      },
      "source": [
        "wcnt=0\n",
        "for i in df['Text_Final']:\n",
        "    wcnt+=len(i.split())\n",
        "print(\"The total number of words are:\", wcnt, sep='\\t')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of words are:\t12273444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVwA0HWs7z8o"
      },
      "source": [
        "Fixing the maximum length of text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSQhF7kW72VA"
      },
      "source": [
        "maxlen=512"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iffee2zFZQ0L"
      },
      "source": [
        "> Dictionary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3G6ANhBJK9X"
      },
      "source": [
        "# Create the term dictionary of our corpus, where every unique term is assigned an index\n",
        "dictionary = corpora.Dictionary(len_filtered_words)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IWTr7Mvl7i7"
      },
      "source": [
        "Finding the size of vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx5zLN47myWX",
        "outputId": "a2fdce84-0729-477a-bf37-4627366b70a3"
      },
      "source": [
        "#total vocabulary size before filtering\n",
        "print(\"Total vocabulary size: \", len(dictionary))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total vocabulary size:  157008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCMUADIJmL1L"
      },
      "source": [
        "vocab_size=len(dictionary)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEzxlUmi9FqD"
      },
      "source": [
        "#Preparing the Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVrDZN5F8vkk"
      },
      "source": [
        "#Splitting into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_test,y_tr,y_test=train_test_split(np.array(df['Text_Final']),y_cat,test_size=0.10,random_state=42,shuffle=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E_AB742SzLH"
      },
      "source": [
        "#Further splitting the train set into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(x_tr,y_tr,test_size=0.10,random_state=42,shuffle=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoEPMLyv_MKD"
      },
      "source": [
        "#Tokenizing the Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc3azyom2FT3"
      },
      "source": [
        "#prepare a tokenizer for reviews\n",
        "x_tokenizer = Tokenizer(num_words=vocab_size, oov_token=None) \n",
        "x_tokenizer.fit_on_texts(list(x_tr)+list(x_val)+list(x_test))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "x_test_seq   =   x_tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "word_index=x_tokenizer.word_index\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=maxlen, padding='post', truncating='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=maxlen, padding='post', truncating='post')\n",
        "x_test  =   pad_sequences(x_test_seq, maxlen=maxlen, padding='post', truncating='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "#vocab_size   =  len(x_tokenizer.word_index) + 1\n",
        "vocab_size+=1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke3A8lRE-3TC"
      },
      "source": [
        "#Transformer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHM-RDsjS3KN"
      },
      "source": [
        "## Implement multi head self attention as a Keras layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysz4Lzg-S3KO"
      },
      "source": [
        "\n",
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNi-YzS3S3KO"
      },
      "source": [
        "## Implement a Transformer block as a layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFq6hoF_eAAH"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "\n",
        "        #Selective Learn and Forget Layer\n",
        "        self.sl1=keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"sigmoid\"), layers.Dense(embed_dim),])\n",
        "        \n",
        "        #Feed forward layer customized for Selective Learning\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"tanh\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "\n",
        "        out2=self.sl1(out1)\n",
        "        ffn_output = out2*self.ffn(out1)\n",
        "\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhJ6_FM6S3KO"
      },
      "source": [
        "## Implement embedding layer\n",
        "\n",
        "Three tier embedding i. Token embedding, ii. Position Embedding iii. Part of Speech embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-LOT6AwZwlE"
      },
      "source": [
        "#Training Word2Vec model upon the vocabulary\n",
        "word2vec_model = gensim.models.Word2Vec(len_filtered_words, size=32, min_count = 1, window = 5)\n",
        "word_model=word2vec_model.wv"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRU-mez2YmyL"
      },
      "source": [
        "Part of Speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LxLTuxhXShuP",
        "outputId": "95935076-07cc-4317-8c88-8dd75b256025"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive   \n",
              "1  A wonderful little production. <br /><br />The...  positive   \n",
              "2  I thought this was a wonderful way to spend ti...  positive   \n",
              "3  Basically there's a family where a little boy ...  negative   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
              "\n",
              "                                          Text_Final  \\\n",
              "0  sostoken one of the other reviewers has mentio...   \n",
              "1  sostoken a wonderful little production septoke...   \n",
              "2  sostoken i thought this was a wonderful way to...   \n",
              "3  sostoken basically theres a family where a lit...   \n",
              "4  sostoken petter matteis love in the time of mo...   \n",
              "\n",
              "                                              Tokens  pos  neg  \n",
              "0  [sostoken, one, of, the, other, reviewers, has...    1    0  \n",
              "1  [sostoken, a, wonderful, little, production, s...    1    0  \n",
              "2  [sostoken, i, thought, this, was, a, wonderful...    1    0  \n",
              "3  [sostoken, basically, theres, a, family, where...    0    1  \n",
              "4  [sostoken, petter, matteis, love, in, the, tim...    1    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6329ed0-8a69-4774-b6c3-0c0c573fa5f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Text_Final</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>pos</th>\n",
              "      <th>neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sostoken one of the other reviewers has mentio...</td>\n",
              "      <td>[sostoken, one, of, the, other, reviewers, has...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sostoken a wonderful little production septoke...</td>\n",
              "      <td>[sostoken, a, wonderful, little, production, s...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sostoken i thought this was a wonderful way to...</td>\n",
              "      <td>[sostoken, i, thought, this, was, a, wonderful...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>sostoken basically theres a family where a lit...</td>\n",
              "      <td>[sostoken, basically, theres, a, family, where...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>sostoken petter matteis love in the time of mo...</td>\n",
              "      <td>[sostoken, petter, matteis, love, in, the, tim...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6329ed0-8a69-4774-b6c3-0c0c573fa5f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6329ed0-8a69-4774-b6c3-0c0c573fa5f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6329ed0-8a69-4774-b6c3-0c0c573fa5f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjf21JTnPFih",
        "outputId": "04741e36-a353-487c-a8a5-598fec8d19ba"
      },
      "source": [
        "part_of_speech=[]\n",
        "for x in tqdm(range(len(df['Text_Final']))):\n",
        "    part_of_speech_t=[]\n",
        "    if len(str(df['Text_Final'][x])) != 0:\n",
        "        lines = str(df['Text_Final'][x]).split('septoken ')\n",
        "        for line in lines:\n",
        "            if line.find('eostoken', 0, len(line))== (-1):\n",
        "                line+='septoken'\n",
        "            doc = nlp(line)\n",
        "            for t in doc:\n",
        "                if (t.text=='sostoken') or (t.text=='eostoken') or (t.text=='septoken'):\n",
        "                    part_of_speech_t.append('SPCL') #Adding POS for special token\n",
        "                else:\n",
        "                    part_of_speech_t.append(t.pos_)\n",
        "    else:\n",
        "        print(\"text length = 0\")\n",
        "    part_of_speech.append(part_of_speech_t)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [1:28:06<00:00,  9.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaz5zZVAjCKf"
      },
      "source": [
        "Finding unique parts of speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXiG9UBlkIO6"
      },
      "source": [
        "unique_pos=[]\n",
        "pos_dictionary = corpora.Dictionary(part_of_speech)\n",
        "for k in pos_dictionary:\n",
        "    unique_pos.append(pos_dictionary[k])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEnzlg6NqS9j"
      },
      "source": [
        "unique_pos=['ADJ', 'ADV', 'AUX', 'DET', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'SPCL', 'VERB', 'INTJ', 'SCONJ', 'CCONJ', 'ADP', 'X', 'PUNCT', 'SYM']"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6-Pt088kk3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d572650-a812-41b9-921e-38726a510238"
      },
      "source": [
        "print(unique_pos)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ADJ', 'ADV', 'AUX', 'DET', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'SPCL', 'VERB', 'INTJ', 'SCONJ', 'CCONJ', 'ADP', 'X', 'PUNCT', 'SYM']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc6uFEmhr_G0"
      },
      "source": [
        "\n",
        "One hot encoding the POS tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrR7WS9Bqoeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d71293-0a2e-483f-fe0b-858eaa293974"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(unique_pos)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  2  3  5  7  8  9 10 11 14 16  6 13  4  1 17 12 15]\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FkYttOQRtm_"
      },
      "source": [
        "Mapping one-hot encoding to POS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FvDlz9ssL8L"
      },
      "source": [
        "#Mapping one-hot encoding to POS\n",
        "pos_dict=dict(zip(unique_pos, onehot_encoded))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Ij6UgrvNIv"
      },
      "source": [
        "word_base=word_model.vocab"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szwKF28WTQpw"
      },
      "source": [
        "Determining POS for terms in vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BxZ7hovTJ07"
      },
      "source": [
        "word_pos=dict()\n",
        "word_posa=dict()\n",
        "for i in range(len(len_filtered_words)):\n",
        "    for j in range(len(len_filtered_words[i])):\n",
        "        if word_base:\n",
        "            if len_filtered_words[i][j] in word_base:\n",
        "                # Mapping part of speech vector\n",
        "                word_pos[len_filtered_words[i][j]]=pos_dict[part_of_speech[i][j]]\n",
        "                # Mapping part of speech\n",
        "                word_posa[len_filtered_words[i][j]]=part_of_speech[i][j]\n",
        "                word_base.pop(len_filtered_words[i][j])\n",
        "        else:\n",
        "            break"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZyQ26CNaUMG"
      },
      "source": [
        "Part of Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJX8-t7BmzpJ"
      },
      "source": [
        "word2vec_model = gensim.models.Word2Vec(len_filtered_words, size=32, min_count = 1, window = 5)\n",
        "word_model=word2vec_model.wv\n",
        "word_base=word_model.vocab"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-schtA3rYRQ"
      },
      "source": [
        "POS Embedding Vector "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8ZxKuC-1o-S"
      },
      "source": [
        "#Preparing a list of word vectors corresponding to each part of speech\n",
        "\n",
        "adj_list=[]\n",
        "adv_list=[]\n",
        "aux_list=[]\n",
        "det_list=[]\n",
        "noun_list=[]\n",
        "num_list=[]\n",
        "part_list=[]\n",
        "pron_list=[]\n",
        "propn_list=[]\n",
        "spcl_list=[]\n",
        "verb_list=[]\n",
        "intj_list=[]\n",
        "sconj_list=[]\n",
        "cconj_list=[]\n",
        "adp_list=[]\n",
        "x_list=[]\n",
        "punct_list=[]\n",
        "sym_list=[]\n",
        "\n",
        "for i in word_base:\n",
        "    if (word_posa[i]=='ADJ'):\n",
        "        adj_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='ADV'):\n",
        "        adv_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='AUX'):\n",
        "        aux_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='DET'):\n",
        "        det_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='NOUN'):\n",
        "        noun_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='NUM'):\n",
        "        num_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='PART'):\n",
        "        part_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='PRON'):\n",
        "        pron_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='PROPN'):\n",
        "        propn_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='SPCL'):\n",
        "        spcl_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='VERB'):\n",
        "        verb_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='INTJ'):\n",
        "        intj_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='SCONJ'):\n",
        "        sconj_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='CCONJ'):\n",
        "        cconj_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='ADP'):\n",
        "        adp_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='X'):\n",
        "        x_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='PUNCT'):\n",
        "        punct_list.append(word_model[i])\n",
        "    elif (word_posa[i]=='SYM'):\n",
        "        sym_list.append(word_model[i])\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjzySmWoK0Gb"
      },
      "source": [
        "#This function takes the input as a list of vectors having the same POS\n",
        "# and calculates the output as the dimension-wise average of the vectors\n",
        "def avg_vector(pos_type):\n",
        "    avg_vec=[]\n",
        "    try:\n",
        "        for i in range(len(pos_type[0])):\n",
        "            avg_vec_t=[]\n",
        "            for j in range(len(pos_type)):\n",
        "                avg_vec_t.append(pos_type[j][i])\n",
        "            avg_vec_t=np.mean(avg_vec_t)\n",
        "            avg_vec.append(avg_vec_t)\n",
        "        return avg_vec\n",
        "    except:\n",
        "        avg_vec=np.zeros(32, dtype=int)\n",
        "        return list(avg_vec)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta4pS4M3FzHf"
      },
      "source": [
        "#Determining the POS vector\n",
        "adj_pos_vector=avg_vector(adj_list)\n",
        "adv_pos_vector=avg_vector(adv_list)\n",
        "aux_pos_vector=avg_vector(aux_list)\n",
        "det_pos_vector=avg_vector(det_list)\n",
        "noun_pos_vector=avg_vector(noun_list)\n",
        "num_pos_vector=avg_vector(num_list)\n",
        "part_pos_vector=avg_vector(part_list)\n",
        "pron_pos_vector=avg_vector(pron_list)\n",
        "propn_pos_vector=avg_vector(propn_list)\n",
        "spcl_pos_vector=avg_vector(spcl_list)\n",
        "verb_pos_vector=avg_vector(verb_list)\n",
        "intj_pos_vector=avg_vector(intj_list)\n",
        "sconj_pos_vector=avg_vector(sconj_list)\n",
        "cconj_pos_vector=avg_vector(cconj_list)\n",
        "adp_pos_vector=avg_vector(adp_list)\n",
        "x_pos_vector=avg_vector(x_list)\n",
        "punct_pos_vector=avg_vector(punct_list)\n",
        "sym_pos_vector=avg_vector(sym_list)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg9HIw9DIILJ"
      },
      "source": [
        "#Combining POS vector as a list\n",
        "pos_vector_list=[]\n",
        "pos_vector_list.append(adj_pos_vector)\n",
        "pos_vector_list.append(adv_pos_vector)\n",
        "pos_vector_list.append(aux_pos_vector)\n",
        "pos_vector_list.append(det_pos_vector)\n",
        "pos_vector_list.append(noun_pos_vector)\n",
        "pos_vector_list.append(num_pos_vector)\n",
        "pos_vector_list.append(part_pos_vector)\n",
        "pos_vector_list.append(pron_pos_vector)\n",
        "pos_vector_list.append(propn_pos_vector)\n",
        "pos_vector_list.append(spcl_pos_vector)\n",
        "pos_vector_list.append(verb_pos_vector)\n",
        "pos_vector_list.append(intj_pos_vector)\n",
        "pos_vector_list.append(sconj_pos_vector)\n",
        "pos_vector_list.append(cconj_pos_vector)\n",
        "pos_vector_list.append(adp_pos_vector)\n",
        "pos_vector_list.append(x_pos_vector)\n",
        "pos_vector_list.append(punct_pos_vector)\n",
        "pos_vector_list.append(sym_pos_vector)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZNWUsjPMWvZ"
      },
      "source": [
        "#Mapping POS vector encoding to POS\n",
        "pos_dict_v=dict(zip(unique_pos, pos_vector_list))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JEiieVraTsa"
      },
      "source": [
        "word_model1=dict()\n",
        "for word in word_base:\n",
        "    word_model1[word]=np.concatenate((word_model[word],pos_dict_v[word_posa[word]]))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkFC6vznsb6m"
      },
      "source": [
        "Preparing the embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPx3QBxRsu8q"
      },
      "source": [
        "embed_dim=64 #For vector POS"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FnhzphYsbJ7"
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_base) + 1, embed_dim))\n",
        "for word in word_base:\n",
        "    embedding_vector = word_model1[word]\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[word_index[word]] = embedding_vector\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzLzTXjEM9oc"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, weights=[embedding_matrix], input_length=maxlen)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjggRfX3S3KR"
      },
      "source": [
        "## Classifier model using transformer layer\n",
        "\n",
        "Transformer layer outputs one vector for each time step of our input sequence.\n",
        "Here, we take the mean across all time steps and\n",
        "use a feed forward network on top of it to classify text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6KYPy4u4cQ7"
      },
      "source": [
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "#embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim) #Method 2\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = transformer_block(x)\n",
        "x = transformer_block(x)\n",
        "x = transformer_block(x)\n",
        "x = transformer_block(x)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81aovTlOYits",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314da07f-d8e4-4910-8815-b177fbd9b10c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " token_and_position_embedding (  (None, 512, 64)     10081344    ['input_1[0][0]']                \n",
            " TokenAndPositionEmbedding)                                                                       \n",
            "                                                                                                  \n",
            " transformer_block (Transformer  (None, 512, 64)     21088       ['token_and_position_embedding[0]\n",
            " Block)                                                          [0]',                            \n",
            "                                                                  'transformer_block[0][0]',      \n",
            "                                                                  'transformer_block[1][0]',      \n",
            "                                                                  'transformer_block[2][0]',      \n",
            "                                                                  'transformer_block[3][0]',      \n",
            "                                                                  'transformer_block[4][0]']      \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 64)          0           ['transformer_block[5][0]']      \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 20)           1300        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 20)           0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 2)            42          ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,103,774\n",
            "Trainable params: 10,103,774\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVjtabEaS3KR"
      },
      "source": [
        "# Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnUhO-H5Cbbw"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp = ModelCheckpoint(filepath='trfr_best_model.h5', monitor='val_categorical_accuracy', save_weights_only=True, verbose=1, save_best_only=True, mode='max')"
      ],
      "metadata": {
        "id": "tXE8RSsBmVec"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybiq1DyNAvLP"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt=tf.keras.optimizers.Adam(learning_rate=0.0001)"
      ],
      "metadata": {
        "id": "nn-GM2bfz_yD"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-qkcT7xS3KR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e029ef5-33a7-4801-b1cd-1386e41c48ec"
      },
      "source": [
        "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
        "history = model.fit(\n",
        "    x_tr, y_tr, batch_size=32, epochs=10, callbacks=[es,cp], validation_data=(x_val, y_val)\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 888/1266 [====================>.........] - ETA: 35s - loss: 0.5322 - categorical_accuracy: 0.7321"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgzaHudRnbyN"
      },
      "source": [
        "# Evaluation of Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL8cGQabCnNQ"
      },
      "source": [
        "y_hat=model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji-3-6lrz6yh"
      },
      "source": [
        "Converting y_val to 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH1eDluMKG19"
      },
      "source": [
        "y_sent=[]\n",
        "for i in y_test:\n",
        "    y_sent.append(1-np.argmax(i)) #This is done to represent argmax=0 as positve and argmax=1 as negative."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N1btueNGFTo"
      },
      "source": [
        "y_hat_sent=[]\n",
        "for i in y_hat:\n",
        "    y_hat_sent.append(1-np.argmax(i)) #This is done to represent argmax=0 as positve and argmax=1 as negative."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAbE9scn646Z"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from itertools import chain\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "import matplotlib.pyplot as plt\n",
        "fpr, tpr, threshold = roc_curve(y_sent, y_hat[:,0])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "#This part is for the confusion matrix and accuracy score\n",
        "cf_matrix = confusion_matrix(y_sent, y_hat_sent) \n",
        "print ('Confusion Matrix :')\n",
        "print(cf_matrix) \n",
        "print ('Accuracy Score :',accuracy_score(y_sent, y_hat_sent))\n",
        "print ('Report : ')\n",
        "print (classification_report(y_sent, y_hat_sent) )\n",
        "#\n",
        "\n",
        "plt.figure(figsize=(8,7))\n",
        "plt.plot(fpr, tpr, label='Model (area = %0.3f)' % roc_auc, linewidth=2)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([-0.05, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=18)\n",
        "plt.ylabel('True Positive Rate', fontsize=18)\n",
        "plt.title('Receiver operating characteristic: is positive', fontsize=18)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}